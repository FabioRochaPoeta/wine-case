{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'opinion' variable based on 'quality'\n",
    "data['opinion'] = data['quality'].apply(lambda x: 0 if x <= 5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the variables present in the dataset\n",
    "variables = {\n",
    "    'fixed acidity': 'continuous',\n",
    "    'volatile acidity': 'continuous',\n",
    "    'citric acid': 'continuous',\n",
    "    'residual sugar': 'continuous',\n",
    "    'chlorides': 'continuous',\n",
    "    'free sulfur dioxide': 'continuous',\n",
    "    'total sulfur dioxide': 'continuous',\n",
    "    'density': 'continuous',\n",
    "    'pH': 'continuous',\n",
    "    'sulphates': 'continuous',\n",
    "    'alcohol': 'continuous',\n",
    "    'quality': 'discrete',\n",
    "    'opinion': 'categorical'\n",
    "}\n",
    "\n",
    "means = data.mean()\n",
    "stds = data.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Select features and target variable\n",
    "X = data.drop(['quality', 'opinion'], axis=1)\n",
    "y = data['opinion']\n",
    "\n",
    "# Initialize logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Perform stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "# Calculate metrics using cross_validate\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "results = cross_validate(logreg, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "# Calculate means and standard deviations of the obtained metrics\n",
    "mean_accuracy = results['test_accuracy'].mean()\n",
    "std_accuracy = results['test_accuracy'].std()\n",
    "\n",
    "mean_precision = results['test_precision'].mean()\n",
    "std_precision = results['test_precision'].std()\n",
    "\n",
    "mean_recall = results['test_recall'].mean()\n",
    "std_recall = results['test_recall'].std()\n",
    "\n",
    "mean_f1 = results['test_f1'].mean()\n",
    "std_f1 = results['test_f1'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize decision tree model\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Perform stratified cross-validation\n",
    "results = cross_validate(dtree, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "# Calculate means and standard deviations of the obtained metrics\n",
    "mean_accuracy_dtree = results['test_accuracy'].mean()\n",
    "std_accuracy_dtree = results['test_accuracy'].std()\n",
    "\n",
    "mean_precision_dtree = results['test_precision'].mean()\n",
    "std_precision_dtree = results['test_precision'].std()\n",
    "\n",
    "mean_recall_dtree = results['test_recall'].mean()\n",
    "std_recall_dtree = results['test_recall'].std()\n",
    "\n",
    "mean_f1_dtree = results['test_f1'].mean()\n",
    "std_f1_dtree = results['test_f1'].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize SVM model\n",
    "svm = SVC()\n",
    "\n",
    "# Perform stratified cross-validation\n",
    "results = cross_validate(svm, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "# Calculate means and standard deviations of the obtained metrics\n",
    "mean_accuracy_svm = results['test_accuracy'].mean()\n",
    "std_accuracy_svm = results['test_accuracy'].std()\n",
    "\n",
    "mean_precision_svm = results['test_precision'].mean()\n",
    "std_precision_svm = results['test_precision'].std()\n",
    "\n",
    "mean_recall_svm = results['test_recall'].mean()\n",
    "std_recall_svm = results['test_recall'].std()\n",
    "\n",
    "mean_f1_svm = results['test_f1'].mean()\n",
    "std_f1_svm = results['test_f1'].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "# Plot average ROC curves for each model\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Logistic Regression\n",
    "logreg_disp = plot_roc_curve(logreg, X, y, name='Logistic Regression')\n",
    "\n",
    "# Decision Tree\n",
    "dtree_disp = plot_roc_curve(dtree, X, y, ax=plt.gca(), name='Decision Tree')\n",
    "\n",
    "# SVM\n",
    "svm_disp = plot_roc_curve(svm, X, y, ax=plt.gca(), name='SVM')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Average ROC Curve Comparison')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter red wine data\n",
    "red_wine = data[data['type'] == 'red'].copy()\n",
    "\n",
    "# Split red wine data\n",
    "X_red = red_wine.drop(['quality', 'opinion'], axis=1)\n",
    "y_red = red_wine['opinion']\n",
    "\n",
    "# Scale red wine data using the same scaler from white wine data\n",
    "X_red_scaled = scaler.transform(X_red)\n",
    "\n",
    "# Make predictions using the logistic regression model\n",
    "y_pred_red = logreg.predict(X_red_scaled)\n",
    "\n",
    "# Calculate metrics for red wine data\n",
    "accuracy_red = accuracy_score(y_red, y_pred_red)\n",
    "precision_red = precision_score(y_red, y_pred_red)\n",
    "recall_red = recall_score(y_red, y_pred_red)\n",
    "f1_score_red = f1_score(y_red, y_pred_red)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d143691b3b796dfa840125b678cbcfa24de4daa9df447a44f4f360662660234b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
